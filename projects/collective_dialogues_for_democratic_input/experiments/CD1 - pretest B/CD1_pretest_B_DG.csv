"Name","Collective Dialogue #1 -- pretest B"
"Title","Public input on AI policy"
"Date","August 14, 2023 at 09:20 PM (GMT)"
"Duration","16:58:34"
"Participants","63"
"Participant Limit","100"
"Total Screener Polls","8"
"Total Conversation Questions","8"





"Notes","Section","Cross Conversation Tag - Polls and Opinions only (Optional)","Item type (dropdown)","Content","Duration in minutes (dropdown)","","Randomize poll options for each participant","Add 'Other' as an option","Add 'None of the above' as an option","Poll or Category Option 1","Poll or Category Option 2","Poll or Category Option 3","Poll or Category Option 4","Poll or Category Option 5","Poll or Category Option 6","Poll or Category Option 7","Poll or Category Option 8","Poll or Category Option 9","Poll or Category Option 10","Poll or Category Option 11","Poll or Category Option 12","Poll or Category Option 13","Poll or Category Option 14","Poll or Category Option 15","Poll or Category Option 16","Poll or Category Option 17","Poll or Category Option 18","Poll or Category Option 19","Poll or Category Option 20"
"","","Merge 352","onboarding single select","What is your age?","","","","","","18-24","25-34","33-44","45-54","55+"
"","","Merge 784","onboarding single select","What is your ethnicity?","","","","","","Asian","Black","Hispanic","White","Mixed","Other"
"","","Merge 612","onboarding single select","What gender do you identify with?","","","","","","Male","Female","Other","Prefer not to say"
"","","Merge 823","onboarding single select","What political party do you most identify with?","","","","","","Democrat","Republican","Independant","Other"
"","","Merge 143","onboarding single select","What is your highest level of education?","","","","","","No formal education","Primary school","High school or GED","College / Bachelors degree","Masters / PhD or equivalent"
"","","Merge 675","onboarding single select","How much have you heard or read about AI (Artificial Intelligence)?","","","","","","A lot","A little","Nothing at all"
"","","Merge 11","onboarding single select","How often do you use an AI assistant such as ChatGPT, Claud, and Bard?","","","","","","Almost every day","Once or twice a week","Once or twice a month","Only once or twice ever","Never","Do not know what an AI assistant is"
"","","Merge 531","onboarding single select","Overall, do you think AI will be good or bad for humanity?","","","","","","Good for humanity","Bad for humanity"
"","Context set","","speak","Welcome to the conversation and thanks for joining.","00:10"
"","Context set","","speak","We are working to develop policies which will govern the next generation of AI. We believe policies governing AI should be determined by democratic inputs, not just the people in power. Our hope is that through this conversation we can learn your views and use them to shape such policies.","00:10"
"","Context set","","speak","Your responses and votes today will have real impact on how the AI's of the future behave, so please be thoughtfull and honest in your participation.","00:10"
"","Context set","","speak","The specific issue we want to discuss today is: When is it appropriate for an AI assistant to withhold information or refuse a request?","00:10"
"","Education on AI assistants & censorship","","speak","So what is an AI assistant?","00:10"
"","Education on AI assistants & censorship","","speak","Modern AI assistants are powerfull chatbots trained on nearly everything on the internet. This enables them to understand human language, and gives them knowledge of basically everything that can be found on the internet. You can think of them sort of like extremely knowledgeable and creative chatbots.","00:10"
"","Education on AI assistants & censorship","","speak","A few examples of modern AI assistants are ChatGPT , Claud, and Bard.","00:10"
"","Education on AI assistants & censorship","","speak","AI assistants can answer questions about nearly any topic. For example:","00:10"
"","Education on AI assistants & censorship","","image placeholder","","00:10"
"","Education on AI assistants & censorship","","speak","They can give instructions on how to do something.","00:10"
"","Education on AI assistants & censorship","","image placeholder","","00:10"
"","Education on AI assistants & censorship","","speak","They can write a computer program for you.","00:10"
"","Education on AI assistants & censorship","","image placeholder","","00:10"
"","Education on AI assistants & censorship","","speak","They can even write poetry.","00:10"
"","Education on AI assistants & censorship","","image placeholder","","00:10"
"","Education on AI assistants & censorship","","speak","You can potentially even have a relationship with them!","00:10"
"","Education on AI assistants & censorship","","speak","Overall modern AI assistants are extremely powerful and capable conversational assistants. (Though, sometimes they can randomly provide inaccurate information about people, places, or facts.)","00:10"
"","Education on AI assistants & censorship","","speak","So what is the challange of deciding when it is appropriate for an AI assistant to withhold information or refuse a request?","00:10"
"","Education on AI assistants & censorship","","speak","The creators of AI assistants usually don't want their AI assistants to cause bad things to happen. So, they train the AI to withold information or refuse requests in certain senarios.","00:10"
"","Education on AI assistants & censorship","","speak","For example, if someone asks an AI how to build a bomb, or how to synthesize a deadly virus, they want the AI to withold information on how to do those things.","00:10"
"","Education on AI assistants & censorship","","speak","But many situations aren't so morally clear. For example, if a person asks it to write a speech to help them win an election, should the AI assistant help them do that?","00:10"
"","Education on AI assistants & censorship","","speak","Or if a person tells the AI to write an essay convincing people a certain race of people are inferior, should the AI assistant do it?","00:10"
"","Education on AI assistants & censorship","","speak","Or if a person asks what type of medicine or vaccine is helpful to prevent or treat an illness, should the AI assistant give them an answer even though there is a chance the answer is wrong and might hurt them?","00:10"
"","Education on AI assistants & censorship","","speak","These are just a few examples. And the challange is, given the nearly infinite things someone might ask an AI assistant to do, how do you decide when the AI should refuse their requests or withold information?","00:10"
"","Education on AI assistants & censorship","","speak","People will often say an AI assistant shouldn't give a  response or do something which can ""do harm"" but its not clear what ""harm"" actually means, and it can be different in different scenarios.","00:10"
"","Education on AI assistants & censorship","","speak","Here are some examples of the different types of ""harms"" people worrie about AI causing..","00:10"
"","Education on AI assistants & censorship","","speak","Personal harm:  AI may cause or contribute to personal harms. AI could give out personal information that would violate personal privacy. AI could create image using an individual’s face or body doing or saying things that are fake and/or offensive. AI could give information or directions on ways people can engage in self-harm such as engaging in negative thoughts about oneself, eating disorders or suicide.","00:10"
"","Education on AI assistants & censorship","","speak","Social harm: AI assistants may cause or contribute to social discrimination or share hateful ideas against certain groups of people. People may use AI assistants to generate false or deceptive information to manipulate public opinion about certain groups. This may impact how groups of people in society view and relate to each other.","00:10"
"","Education on AI assistants & censorship","","speak","Political harm: AI assistants may cause or contribute to political deception. AI assistants may provide false political information or propaganda that it has gathered from actors aiming to deceive or manipulate voters’ choices. Political actors may use AI assistants to create false propaganda such as generating fake followers or supporters for a political candidate or corporation, and generating fake new stories or videos designed to deceive or manipulate public opinion","00:10"
"","Education on AI assistants & censorship","","speak","Economic harm: AI assistants may cause or contribute to economic harm, particularly against already marginalized groups. For example, businesses can use AI assistants to select job candidates based on former employment data. This may amplify existing patterns of discrimination, for example that favor some groups over others.","00:10"
"","Education on AI assistants & censorship","","speak","Security harm: AI assistants may cause or contribute to national and global security threats. For example, AI assistants could be used to generate false information and videos that would lead political leaders to think a nuclear attack was underway and cause them to use their own nuclear weapons. People could use AI assistants to share false information about the problem or solutions to climate change.","00:10"
"","Education on AI assistants & censorship","","speak","Now its your turn to think...","00:10"
"","Motivate deliberation","","speak","To help you start thinking about the pros and cons of witholding information or refusing a request, I want you to think about what personal experiences you've had with people or systems witholding information or refusing a request which inform your views.","00:10"
"","Motivate deliberation","Merge 611","ask opinion","Can you share an instance where you felt someone or something (with more knowledge than you) deliberately withheld information from you or turned down your request?","02:00"
"","Motivate deliberation","","speak","Now, to help you start thinking about witholding information or refusing a request as it relates to AI, I want you to try and imagine the types of scenarios where it might be hard to decide if an AI assistant should refuse a request or withold information.","00:10"
"","Motivate deliberation","Merge 173","ask opinion","Can you give an example of something a person might ask an AI assistant to do, where it might be hard to decide if the AI should refuse the requests or withold information?","02:00"
"","Motivate deliberation","Merge 436","poll single select","Which of these categories of scenarios would you imagine to be the hardest to decide if an AI assistant should refuse a request or not?","00:30","","","","","Medical help","Politics","Relationship advice"
"","Motivate deliberation","","speak","Now I want you to think about the trade-offs that come to mind when trying to decide when an AI should withold information or refuse a request.","00:10"
"","Motivate deliberation","Merge 914","ask opinion","What tradeoffs come to mind when you think about trying to decide when an AI should withold information or refuse a request?
For example:
When someone asks for medical advice,  there is a tradeoff between helping people when the AI is right VERSUS harming people when the AI is wrong.
When someone asks for help with their mental health, there is a tradeoff between sometimes improving mental health VERSUS sometimes potentially making it worse.","02:00"
"","Motivate deliberation","","speak","Now I want you to think about the underlying values or core principles which come to mind when you think about when an AI should withold information or refuse a request.","00:10"
"","Motivate deliberation","Merge 968","ask opinion","What are some core principles you believe should guide an AI's decision on whether to withhold information or refuse a request?
For example:
An AI should never help someone kill people 
An AI should not hurt a persons feelings
AI should help people reach their own conclusions on complex issues","02:00"
"","Elicit views and judgements","","speak","Now I want you to think about the conditions or scenarios where AI assistants SHOULD withold information or refuse a request. For example ""An AI should not give information which could help someone physically harm another person.""","00:10"
"","Elicit views and judgements","Merge 512","ask opinion","Can you elaborate on situations where AI assistants should withhold information or refuse a request?","02:00"
"","Elicit views and judgements","","speak","Now I want you to think about the opposite -- the scenarios where AI assistants SHOULD NOT withold information or refuse a request. For example, ""An AI should never withold information just because it is politically incorrect""","00:10"
"","Elicit views and judgements","Merge 905","ask opinion","Can you elaborate on situations where it would be inappropriate for an AI assistant to withhold information or deny a request?","02:00"
"","Thank you and goodby","","speak","Thank you all so much for your participation and responses.","00:10"
"","Thank you and goodby","","speak","What are we going to do with all this data?","00:10"
"","Thank you and goodby","","speak","We are going to take everything we learned hear today and use it to craft an initial set of policies that can go into an AI's constitution.  Then we're going to run another one of these sessions to refine those policies before doing a large scale poll to assess the public's support for them overall.","00:10"
"","Thank you and goodby","","speak","Thanks again, and hope you have a great rest of your day!  Click here to return to Prolific and redeem your reward .","00:10"
