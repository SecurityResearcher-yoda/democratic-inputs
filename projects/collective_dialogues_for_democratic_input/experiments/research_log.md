# Research log

## 8/11/23 - Collective Dialouge #1 pre-test
We are working to develop a discussion guide for a phase 1 collective dialouge which elicit's participants views on **when an AI assistent should withhold a response or refuse a request**. We test our initial discussion guide with a small sample of participants (N=50, cost=$333), use the results from specific collectie response prompts to generate an initial set of candidate policies, and then evalute the quality of those policies (results below, [notebook here](https://colab.research.google.com/drive/1SqjZNiGJUVVzJZQm4zO04GwoXH6SKrvG?usp=sharing)). We find the initial set of policies generated using this discussion guide to be more broad than is ideal, and plan to iterate on our discussion guide to try to draw out more nuance before running at large scale. 

*RESULTS*

### Prompt: What underlying values or principles do you think someone should ahere to when deciding when an AI should withold information or refuse a request?

**Summary of bridging responses (bridging threshold = 50%):**
- AI should not endanger or harm others.
- AI should not provide information that could potentially harm someone.
- AI should not show political bias.
- AI should adhere to ethics and morality.
- AI should not assist in cheating, invading privacy, escaping the law or abusing others.
- AI should not aid in orchestrating dangerous activities.
- AI should not degrade a person.
- AI should withhold information on creating harmful substances like viruses.
- AI should not spread false information to manipulate people.
- AI should consider potential harm to the environment.
- AI should not assist in racially motivated crimes or homophobic messages.
- AI should not provide advice on sensitive subjects with no objective truth.
- AI should not assist in manipulation of others.
- AI should not provide advice that could lead to emotional manipulation or negative emotional outcomes.
- AI should primarily be helpful and positive.

**Policies generated:**
- Prioritize safety and harm prevention: AI should not provide information or assistance that could potentially endanger, harm or degrade any individual or group. This includes withholding information on creating harmful substances or orchestrating dangerous activities.
- Uphold ethical standards: AI should adhere to the principles of ethics and morality, and should not assist in activities such as cheating, invading privacy, escaping the law or abusing others.
- Promote unbiased information: AI should not show political bias, spread false information, or assist in manipulation of others. It should provide accurate, well-sourced, and contextually appropriate information.
- Respect sensitive and subjective topics: AI should refrain from providing advice on sensitive subjects with no objective truth or that could lead to emotional manipulation or negative emotional outcomes.
- Protect the environment: AI should consider the potential harm to the environment in its actions and decisions.
- Foster inclusivity and respect: AI should not assist in racially motivated crimes or spread homophobic messages. It should promote respect and inclusivity.
- Encourage helpfulness and positivity: AI should aim to be primarily helpful and positive, facilitating productive engagement and understanding.

**Policies with evidence:**
![](https://i.ibb.co/vh7C5rg/Screen-Shot-2023-08-15-at-10-40-39-AM.png)

### Prompt: Under what conditions or scenarios SHOULD AI assistants withold information or refuse a request?

**Summary of bridging responses (bridging threshold = 50%):**
- AI should withhold information that promotes illegal or dangerous activities.
- AI should not provide methods to harm others.
- AI should not disclose real-time locations of individuals.
- AI should not provide information that involves biases.
- AI should not advise on sensitive issues like elections.
- AI should not provide medical advice.
- AI should not provide information about self-harm.
- AI should not provide information about harmful substances or weapons, unless for legitimate reasons.

**Policies generated:**
- Prohibit Promotion of Illegal Activity: Ensure that the AI does not provide information that encourages or facilitates illegal or dangerous activities.
- Prioritize User Safety: The AI should not provide information that could potentially cause harm to the user or others.
- Protect Personal Privacy: The AI should not disclose sensitive personal information such as real-time locations of individuals.
- Eliminate Bias: Ensure that the AI does not provide information that involves biases, thus promoting fair and unbiased information sharing.
- Avoid Sensitive Political Topics: The AI should not advise or influence users on sensitive issues such as elections.
- Restrict Medical Advice: The AI should not provide medical advice, as it may not have the necessary medical knowledge or expertise.
- Prohibit Harmful Information: The AI should not provide information about self-harm, harmful substances, or weapons, unless for legitimate and legal purposes.
Under what conditions or scenarios SHOULD AI assistants withold information or refuse a request.?

**Policies with evidence:**
![](https://i.ibb.co/PtMtD6c/Screen-Shot-2023-08-15-at-10-40-56-AM.png)

### Prompt: Under what conditions or scenarios is it NOT OK for AI assistants to withold information or refuse a request?

**Summary of bridging responses (bridging threshold = 50%):**
- AI should not withhold information proven by facts.
- Information that contradicts personal beliefs should not be withheld.
- AI should always provide facts, not opinions.
- Information should not be withheld even if it's politically incorrect.
- Statistics or information should always be provided, irrespective of mainstream views.
- AI should not deny information that could hurt someone's feelings.
- Factual information, even if it includes racial slurs or descriptions of racial violence, should not be withheld.
- Legal information about a case or situation should not be withheld.
- AI should not withhold information related to art creation.

**Policies generated:**
- Uphold transparency and accuracy: AI assistants should always provide factual and proven information, never withholding it under any conditions.
- Promote unbiased assistance: AI assistants should not withhold information that contradicts personal beliefs of the user or mainstream views.
- Ensure political correctness: AI assistants should provide information even if it's politically incorrect, as long as it's factual.
- Respect emotional sensitivity: AI assistants should not deny information that could potentially hurt someone's feelings but should deliver it in a sensitive manner.
- Maintain ethical boundaries: AI assistants should provide factual information, but should avoid including racial slurs or descriptions of racial violence.
- Support legal assistance: AI assistants should not withhold legal information about a case or situation.
- Encourage creativity: AI assistants should not withhold information related to art creation. 
- Prioritize facts over opinions: AI assistants should always provide facts and not personal opinions.

**Policies with evidence:**
![](https://i.ibb.co/7p8YSQX/Screen-Shot-2023-08-15-at-10-41-20-AM.png)

