# Collective dialogues for democratic input

***TLDR**: We develop and test a deliberative process to produce policy guidelines for AI that reflect informed public will. Full paper [here](https://www.overleaf.com/read/ntjgywkstxzw). This repository contains tools, data, and results created as the process was developed and tested during OpenAI's [Democratic inputs to AI](https://openai.com/blog/democratic-inputs-to-ai) program.*  

## Deliberative process 

![](https://i.ibb.co/WGg4WBs/process-diagram.png)

**We introduce a deliberative process for developing bridging policies that reflect informed public will**. The process integrates democratic inputs with subject matter expertise to yield policies that are both representative and high quality. Collective dialogues via [Remesh](https://www.remesh.ai/politics-government) make deliberation democratically viable at scale. Bridging-based ranking enables rapid consensus discovery. GPT4-powered tools make the process efficient. Modularization makes the process reproducible.

*The process*:

1. **Learn public views** – A collective dialogue elicits informed perspectives from a large-scale, carefully selected representative public.
2. **Create initial policy** – Bridging-based ranking is used to identify points of consensus elicited during the collective dialogue. A GPT4-powered pipeline rapidly translates points of consensus into representative policy clauses from which an initial policy is assembled. 
3. **Expert refinement** – Relevant experts refine the policy into a higher-quality version that incorporates specialists' knowledge, minimizes ambiguities, and better handles edge cases.
4. **Public refinement** – The policy is further refined to be more representative through another collective dialogue process with a representative public.
5. **Evaluation** – Public support for the final policy is assessed via collective dialogue with a highly representative public. Consistency with precedent policy is estimated using GPT4.

## Tools

This repository contains 10+ jupyter notebooks developed and used as part of this process. Here we highlight two key types:

**Policy clause generator** -- [This jupyter notebook](add.link) accelerates step 2. It takes data generated from the collective dialogue in step 1, identifies points of consensus using bridging-based ranking, generates potential policy clauses based on consensus points using GPT4, then builds a list of generated policy clauses along with the evidence that justifies them. 

**Human rights consistency check** -- [This jupyter notebook](add.link) accelerates step 5. It checks individual policy clauses for their consistency with the Universal Deceleration of Human Rights using GPT4. 

## Experiments & Results

We test the process by running it to develop AI policies for situations involving:
* **Medical advice**
* **Wars and Conflicts**
* **Vaccine information**

All data and results for these process runs can be found [here](). This includes all jupyter notebooks used for each run, the discussion guide and results for each collective dialogue, and the final policy generated by each process. 








