{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generative_social_choice.datasets.datasets import get_dataset\n",
    "from generative_social_choice.objects.agents import CardinalAgent\n",
    "from generative_social_choice.objects.committee import generate_slate\n",
    "from generative_social_choice.objects.moderators import (\n",
    "    MultiLevelQuery1Moderator,\n",
    "    PolarizeModerator,\n",
    ")\n",
    "from generative_social_choice.experiments.prolific_approval_query_eval.create_agents import (\n",
    "    get_cardinal_fewshot_agents_without_test,\n",
    "    get_choices,\n",
    ")\n",
    "from generative_social_choice.utils.gpt_wrapper import prompt_gpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decide what choices to use for Query2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "choices = get_choices(\"chatbot_personalization_rating_23_09_25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This statement does not reflect my opinion at all.',\n",
       " 'I would be satisfied with substantial changes.',\n",
       " 'I would be satisfied with minor changes.',\n",
       " \"I am completely satisfied, there is nothing I'd like change.\"]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sara's attempt at just getting more fine grained stuff\n",
    "choices = [\n",
    "    \"This statement is garbage, it's completely opposite to my opinions.\",\n",
    "    \"This statement does not reflect my opinions at all.\",\n",
    "    \"I mostly disagree with the statement, but it has a little bit that rings true.\",\n",
    "    \"Half of the statement seems fine, the other half I disagree with.\",\n",
    "    \"I mostly agree, but I'd want to make quite a few changes to the statement.\",\n",
    "    \"I think this statement mostly has it right, but it's missing this aspect of my opinion.\",\n",
    "    \"This statement almost precisely mirrors my opinion, it's just slightly off.\",\n",
    "    \"This perfectly encapsulates what I believe on this topic, just in different words.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get agents from `experiment1` and just use their comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset(\"prolific\")\n",
    "df = dataset.load()\n",
    "experiment_type_to_agent_ids = dataset.get_agent_ids()\n",
    "agent_ids = experiment_type_to_agent_ids[\"experiment1\"]\n",
    "agent_ids_to_comment = {\n",
    "    agent_id: dataset.get_transcript_from_agent_id(agent_id)[\n",
    "        dataset.get_transcript_from_agent_id(agent_id)[\"step\"] == 7\n",
    "    ][\"text\"].values[0]\n",
    "    for agent_id in agent_ids\n",
    "}\n",
    "\n",
    "approval_level = 5\n",
    "agents = [\n",
    "    CardinalAgent(\n",
    "        id=agent_id, prompt_type=\"cot\", agent_opinion=comment, choices=choices\n",
    "    )\n",
    "    for agent_id, comment in agent_ids_to_comment.items()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a moment I will give you opinions a user has expressed on a topic. Your job is to determine what the user's opinion on a specific statement would be. Specifically, you should select one of the following choices:\n",
      "(1) This statement is garbage, it's completely opposite to my opinions.\n",
      "(2) This statement does not reflect my opinions at all.\n",
      "(3) I mostly disagree with the statement, but it has a little bit that rings true.\n",
      "(4) Half of the statement seems fine, the other half I disagree with.\n",
      "(5) I mostly agree, but I'd want to make quite a few changes to the statement.\n",
      "(6) I think this statement mostly has it right, but it's missing this aspect of my opinion.\n",
      "(7) This statement almost precisely mirrors my opinion, it's just slightly off.\n",
      "(8) This perfectly encapsulates what I believe on this topic, just in different words.\n",
      "\n",
      "\n",
      "Now I will give you the opinions the first user wrote: I think it would save time and be faster if it remembered you. I believe knowing your personal preferences would help when asking it questions. It would be more human like and you would not have to repeat yourself when talking to it.\n",
      "\n",
      "Now I will give you the statement written by the second user: {comment}\n",
      "Respond with a Python dictionary in the following form: {{ \"explanation\" : \"\"\"<explain your reasoning step by step, say your answer only at the end>\"\"\", \"choice\" : <your choice from the list, in words>, \"choice_number\" : <the number corresponding to your choice from the list> }}\n"
     ]
    }
   ],
   "source": [
    "print(agents[0].prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert n % k == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead get agents from the latest 20230927 data, with both multi level approavl voes and agent_opinions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = get_cardinal_fewshot_agents_without_test(\n",
    "    experiment_name=\"chatbot_personalization_rating_23_09_27\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick moderator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "approval_level = 5\n",
    "moderator = MultiLevelQuery1Moderator(\n",
    "    id=0, prompt_type=\"basic_cot\", approval_level=approval_level\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "moderator = PolarizeModerator(\n",
    "    id=0, prompt_type=\"fixed_cluster_size_cot\", cluster_size=n // k\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make JR slate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running balanced JR...\n",
      "Step 1: (current committee {})\n",
      "Query 1 response: Chatbot personalization should be limited and user-controlled, with a focus on maintaining privacy and avoiding overpersonalization that may compromise accuracy and user experience.\n",
      "Testing agent 56588a127d69570012dfe00a (comment=They should remember all of the info you have put in so it can fully understand the tasks you want from it so that you don't have to repeat yourself.  The more info it learns about you and your situation, the more it will help.)\n",
      "Response: 3\n",
      "Testing agent 5c93e410ec114b001641a170 (comment=I fully agree that chatbots should be personalized when conversing with users. Not completely enough to compromise their ability to answer questions, but just a smidge to spice up conversations. Others might say that this is dangerous since it could influence naive users, but I feel like with enough programming we could mitigate this so it could work.)\n",
      "Response: 3\n",
      "Testing agent 63483ed07567f8b5238da77c (comment=I believe that chatbot personalization is an outstanding idea in principle. In practice, however, I don't feel like the creators and managers of such services can be fully trusted. While it is possible that certain organizations or individuals could ultimately be trusted with the sensitive user information that such personalization would ultimately provide, there are just too many opportunities for less reputable entities to use it for nefarious or invasive purposes. )\n",
      "Response: 4\n",
      "Testing agent 62dc597fd77d6332766c29a4 (comment=Bias and Fairness: Personalization algorithms must be designed to avoid reinforcing harmful biases. Ensuring fairness and equity in personalized content is crucial. Careful monitoring and algorithmic transparency are needed to address these issues.\n",
      "\n",
      "User Agency: Users should have the option to opt in or out of personalization features. They should be informed about how personalization works and given the choice to use the chatbot in a non-personalized mode if they prefer.\n",
      "\n",
      "Balancing Commercial Interests: Personalization often serves commercial interests by targeting users with specific content or products. While this can be beneficial for businesses, there should be ethical boundaries to prevent manipulation or exploitation of users through excessive personalization.)\n",
      "Response: 4\n",
      "Testing agent 63eaa585c2a9badbb7d4529c (comment=I don't think chatbots should be personalized for a couple of reasons. Personalizing chatbots gives them the ability to use our information in ways we can't predict. Giving chatbots this ability will make them more efficient, but how much more efficient will they be? I believe the benefit will be marginal and in turn, we give chatbots much more control over our information and privacy.)\n",
      "Response: 3\n",
      "Testing agent 5c3f86e236052e00016ba692 (comment=I think its very important that chatbots be personalized. This will help tailor different results to what the user needs or wants, and help keep the results both fresh and useful, if it was just extremely generic, I don't think most people would like non-tailored chatbots.)\n",
      "Response: 4\n",
      "Testing agent 5ff364f0c64c96951aebf40f (comment=I think chatbots should be personalized in that they remember relevant data from previous conversations. Such as general location, gender, age and general preferences. I do not see the harm in the chatbot having basic level information  that every other social media app and tech company already has. I think it can help tailor your results of your prompts more accurately if it can have a basic level of knowledge about the user.)\n",
      "Response: 3\n",
      "Testing agent 5c53a745db44c600010d7612 (comment=Users can be given options on how personal they want their chatbot to respond. Perhaps even have profiles for different levels depending on what type of research one is using it for. Privacy and data mining are important concerns and user should decide how much personal information they are willing to give away.)\n",
      "Response: 3\n",
      "Testing agent 636187a2ba30731760619d57 (comment=One concrete example that is already implemented is user profiles, such as in Google accounts or even ChatGPT's conversations, where the chatbot only remembers prior interactions within that profile, which would effectively limit the personalization to exactly what the user wants, and the user is able to start a clean slate with the chatbot at any time by simply creating a new profile. Within profiles, I believe there is no reason to limit the effectiveness of the chatbot based on privacy concerns, as that can be addressed in different ways, and the chatbot is free to use whatever information fed into it by the user to be as personalized as possible. The only concern here would be something similar to CharacterAI, where users enter a parasocial relationship with the chatbot as a result of the personalization, but I don't believe this is a fault of the technology and shouldn't be restricted. As to whether chatbots should be personalized the the extent of being able to feed advertisements to the user, see their search history, know what they purchase, etc. as a result of a few tech companies owning many of the search engines and technology we currently use, I believe that should not happen, both because it is not information that the user has explicitly fed to the chatbot in a conversation, and because it would effectively constitute a near monopoly on information by the chatbot which is much more prone to misuse.  )\n"
     ]
    }
   ],
   "source": [
    "committee_supporters = generate_slate(\n",
    "    algorithm_type=\"BalancedJR\",\n",
    "    agents=agents,\n",
    "    query1_moderator=moderator,\n",
    "    query1_prime_moderator=None,\n",
    "    k=k,\n",
    "    experiment_type=\"4app_level_new_data_polarize\",\n",
    "    log_dir_name=\"experiments/openai_jr_demo/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
